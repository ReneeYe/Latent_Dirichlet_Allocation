{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import os\n",
    "\n",
    "#path = os.getcwd()\n",
    "#filename = 'ap/'\n",
    "#full_path = os.path.join(path, filename)\n",
    "#data = pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\@复旦u\\7.大三第二学期\\1.学习\\人工智能\\Final_Project\\LDA_Model_For_Topic_Classification\\Latent_Dirichlet_Allocation-gibbs-perplexity\\experiment_food_data.csv\n"
     ]
    }
   ],
   "source": [
    "#version2 \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "filename = \"experiment_food_data.csv\"\n",
    "full_path = os.path.join(path, filename)\n",
    "print(full_path)\n",
    "food_data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_count(row):\n",
    "    if row[\"Score\"] in [1,2]:\n",
    "        return 1/82012\n",
    "    elif row[\"Score\"] ==3:\n",
    "        return 1/42639\n",
    "    return 1/443777\n",
    "\n",
    "food_data[\"weight\"] =food_data.apply(lambda row:weight_count(row), axis=1)\n",
    "food_data['weight'].head()\n",
    "len(food_data['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>29507</td>\n",
       "      <td>29508</td>\n",
       "      <td>B000PDY3P0</td>\n",
       "      <td>AP1N9Y6K40YNW</td>\n",
       "      <td>Julie</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1342915200</td>\n",
       "      <td>Captures that movie theater taste, but far fro...</td>\n",
       "      <td>I purchased this product for use with my new M...</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>233494</td>\n",
       "      <td>233495</td>\n",
       "      <td>B004WJATHO</td>\n",
       "      <td>A24OX6XLW4L331</td>\n",
       "      <td>OKCJohn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1342224000</td>\n",
       "      <td>You will love it or hate it...no in between</td>\n",
       "      <td>I ordered it but didn't realize that it was fl...</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>512237</td>\n",
       "      <td>512238</td>\n",
       "      <td>B0029K3EJS</td>\n",
       "      <td>AKNCY5WCXLQ4H</td>\n",
       "      <td>Sheryl L. Kok \"Blondie\"</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1255737600</td>\n",
       "      <td>Ok but most cans dented</td>\n",
       "      <td>Obviously this company is off-loading its dent...</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>256578</td>\n",
       "      <td>256579</td>\n",
       "      <td>B003JA5KBW</td>\n",
       "      <td>A7JGEKN140F4S</td>\n",
       "      <td>Keith \"kc31824\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1323907200</td>\n",
       "      <td>Take a vitamin instead</td>\n",
       "      <td>Doesn't taste very good, and I'm not sure the ...</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>8540</td>\n",
       "      <td>8541</td>\n",
       "      <td>B003VXFK44</td>\n",
       "      <td>A2VBTN6ZR67YOF</td>\n",
       "      <td>Mike Jacobs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1306972800</td>\n",
       "      <td>A little too much bitterness &amp; acid</td>\n",
       "      <td>This is less of a \"bold\" flavor and more of an...</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num      Id   ProductId          UserId              ProfileName  \\\n",
       "945    29507   29508  B000PDY3P0   AP1N9Y6K40YNW                    Julie   \n",
       "1316  233494  233495  B004WJATHO  A24OX6XLW4L331                  OKCJohn   \n",
       "1228  512237  512238  B0029K3EJS   AKNCY5WCXLQ4H  Sheryl L. Kok \"Blondie\"   \n",
       "124   256578  256579  B003JA5KBW   A7JGEKN140F4S          Keith \"kc31824\"   \n",
       "1455    8540    8541  B003VXFK44  A2VBTN6ZR67YOF              Mike Jacobs   \n",
       "\n",
       "      HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "945                      2                       2      3  1342915200   \n",
       "1316                     0                       0      3  1342224000   \n",
       "1228                    15                      15      3  1255737600   \n",
       "124                      0                       0      3  1323907200   \n",
       "1455                     0                       0      3  1306972800   \n",
       "\n",
       "                                                Summary  \\\n",
       "945   Captures that movie theater taste, but far fro...   \n",
       "1316        You will love it or hate it...no in between   \n",
       "1228                            Ok but most cans dented   \n",
       "124                              Take a vitamin instead   \n",
       "1455                A little too much bitterness & acid   \n",
       "\n",
       "                                                   Text    weight  \n",
       "945   I purchased this product for use with my new M...  0.000023  \n",
       "1316  I ordered it but didn't realize that it was fl...  0.000023  \n",
       "1228  Obviously this company is off-loading its dent...  0.000023  \n",
       "124   Doesn't taste very good, and I'm not sure the ...  0.000023  \n",
       "1455  This is less of a \"bold\" flavor and more of an...  0.000023  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_data_for_experiment = food_data.sample(n=1500,random_state=1314,weights=food_data.weight)\n",
    "food_data_for_experiment.to_csv(\"experiment_food_data.csv\",sep=',')\n",
    "food_data_for_experiment.groupby(\"Score\").count()\n",
    "food_data_for_experiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       I purchased this product for use with my new M...\n",
      "1       I ordered it but didn't realize that it was fl...\n",
      "2       Obviously this company is off-loading its dent...\n",
      "3       Doesn't taste very good, and I'm not sure the ...\n",
      "4       This is less of a \"bold\" flavor and more of an...\n",
      "5       So far the one box I opened didn't make me sic...\n",
      "6       Got the my order, opened the box, and the firs...\n",
      "7       I love coffee and I start my day with it and I...\n",
      "8       this price is a joke right? the cherries and b...\n",
      "9       I'd like to try something different and chose ...\n",
      "10      This is my first bag of chai tea and I have to...\n",
      "11      Okay, I admit it, I'm a red licorice junkie. B...\n",
      "12      Shipment arrived as scheduled. Fish was partia...\n",
      "13      This coffee is ok, but nothing great, at least...\n",
      "14      I bought one of the Stash teas-don't remember ...\n",
      "15      The rating is driven by the purchase of whole ...\n",
      "16      It's not bad. Good ingredients for a change so...\n",
      "17      I loved the idea of this snack. As others ment...\n",
      "18      Bear Naked Granola, especially the Fruit & Nut...\n",
      "19      These taste very good and are quick and easy. ...\n",
      "20      These look a lot like a sweet treat when you f...\n",
      "21      I have eight of these bottles sitting in my cu...\n",
      "22      Since I love French Roast, I was happy to get ...\n",
      "23      This was an impulse buy. I purchased other foo...\n",
      "24      Expected some brand variety and paid more than...\n",
      "25      Wow.<br />This gingerbread is terrible. Truly ...\n",
      "26      I know marketers try to make magic by using th...\n",
      "27      The cookies were delicious but the arrived in ...\n",
      "28      Same SlimJim taste I remembered, and I like th...\n",
      "29      I'm a fan of other baked chip products (such a...\n",
      "                              ...                        \n",
      "1470    My dogs think these Chicken Zuke's Minis are r...\n",
      "1471    I bought these Arizona Green Tea packets becau...\n",
      "1472    I must say that this was a great offer.  I use...\n",
      "1473    I love the way that this K-Cup Carousel holds ...\n",
      "1474    They're light, but so tasy! The sweetness if v...\n",
      "1475    Our family absolutely loves Heartland's waffle...\n",
      "1476    In my opinion Orgain is by far the best power ...\n",
      "1477    I like a quick cup of coffee in the morning (t...\n",
      "1478    I love stash decaf chai it is very good. I lov...\n",
      "1479    I use Arrowhead Mills Puffed Corn for breakfas...\n",
      "1480    I was hooked from the first time tasting Ting....\n",
      "1481    Kettle brand Baked Potato Chips are the best b...\n",
      "1482    I love all things banana and this syrup meets ...\n",
      "1483    These nutrition-packed bars are delicious and ...\n",
      "1484    You can never go wrong with Popchips if you're...\n",
      "1485    When looking for a gluten free product taste i...\n",
      "1486    If you're feeding a large family, or use water...\n",
      "1487    Wonderful, meaty vanilla beans! I've used vani...\n",
      "1488    I haven't ordered this item YET, so I can't sp...\n",
      "1489    My favorite snack is popcorn and there are so ...\n",
      "1490    This coffee was actually better than I expecte...\n",
      "1491    Great taste, and high protein. These are my fa...\n",
      "1492    Fantastic price and great service. Roland is a...\n",
      "1493    My daughter is allergic to soy and I was SO ha...\n",
      "1494    The only reason I purchased the set was for th...\n",
      "1495    Great Ingredients - lousy taste<br /><br />I b...\n",
      "1496    I use pedigree products and I am quiet satisfi...\n",
      "1497    Taste is a personal issue so I won't comment o...\n",
      "1498    Good wing sauce had a bbq and everyone one ate...\n",
      "1499    My baby girl loves this flavor. Apples have al...\n",
      "Name: Text, dtype: object\n",
      "Next time plz add random_seed here!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "listdir: embedded null character in path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-06bc733ba36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTOPIC_MODEL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtp_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfood_review_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_topic\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mn_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_prop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mperplexity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"perlexity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpresent_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\@复旦u\\7.大三第二学期\\1.学习\\人工智能\\Final_Project\\LDA_Model_For_Topic_Classification\\Latent_Dirichlet_Allocation-gibbs-perplexity\\Topic_Modelling.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, allcontent, num_topic, train_prop, **kwarg)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_topic\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_topic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mtest_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\@复旦u\\7.大三第二学期\\1.学习\\人工智能\\Final_Project\\LDA_Model_For_Topic_Classification\\Latent_Dirichlet_Allocation-gibbs-perplexity\\LDA_Gibbs_Sampling.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, textfiles_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mTerm\u001b[0m \u001b[0mMatrix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0mmodelling\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \t\t'''\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath2corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextfiles_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\@复旦u\\7.大三第二学期\\1.学习\\人工智能\\Final_Project\\LDA_Model_For_Topic_Classification\\Latent_Dirichlet_Allocation-gibbs-perplexity\\util.py\u001b[0m in \u001b[0;36mpath2corpus\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpath2corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtxt_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtxt_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mvectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'filename'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlowercase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: listdir: embedded null character in path"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "##########################Experiment Code\n",
    "import pandas as pd\n",
    "import os\n",
    "from Topic_Modelling import TOPIC_MODEL\n",
    "import numpy as np\n",
    "import re \n",
    "import time \n",
    "\n",
    "path = os.getcwd()\n",
    "filename = \"experiment_food_data.csv\"\n",
    "full_path = os.path.join(path, filename)\n",
    "\n",
    "food_data = pd.read_csv(filename,delimiter= \",\")\n",
    "food_review_data= food_data.Text\n",
    "title = food_data.Summary\n",
    "\n",
    "print(food_review_data)\n",
    "\n",
    "start_time= time.time()\n",
    "perplexity = list()\n",
    "\n",
    "#assign number of topic here.\n",
    "for n_t in [10, 15, 20, 30, 50, 80]:\n",
    "    tp_model = TOPIC_MODEL()\n",
    "    model= tp_model.fit(food_review_data,num_topic= n_t,train_prop=0.9)\n",
    "    perplexity.append(model.results[\"perlexity\"])\n",
    "    present_time = time.time()\n",
    "    print(\"This iteration --- %s seconds ---\".format(round(present_time - start_time,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4851.562335968018"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1497001573.723447 - 1496996722.161111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
